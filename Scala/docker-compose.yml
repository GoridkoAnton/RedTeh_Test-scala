version: "3.8"

services:
  postgres:
    image: postgres:13
    restart: unless-stopped
    environment:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-airflow} -d ${POSTGRES_DB:-airflow} -h 127.0.0.1 -p 5432"]
      interval: 5s
      timeout: 3s
      retries: 20

  airflow:
    image: apache/airflow:2.7.1
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - SPARK_DRIVER_MEMORY=${SPARK_DRIVER_MEMORY:-20g}
      - SPARK_DRIVER_MEMORY_OVERHEAD=${SPARK_DRIVER_MEMORY_OVERHEAD:-2g}
      - CONTAINER_MEM_LIMIT=${CONTAINER_MEM_LIMIT:-24g}
      - SPARK_MASTER=${SPARK_MASTER:-local[4]}
    volumes:
      - ./dags:/opt/airflow/dags:ro
      - /data:/data:rw
      - /var/run/docker.sock:/var/run/docker.sock
      - airflow_logs:/opt/airflow/logs
      - airflow_plugins:/opt/airflow/plugins
    # ENTRYPOINT: инициализация выполняется только один раз внутри контейнера (флаг /home/airflow/.initialized)
    entrypoint: ["/bin/bash", "-c", "\
      set -euo pipefail; \
      echo 'Waiting for Postgres...'; \
      if command -v pg_isready >/dev/null 2>&1; then \
        until pg_isready -h \"${POSTGRES_HOST:-postgres}\" -p \"${POSTGRES_PORT:-5432}\" -U \"${POSTGRES_USER:-airflow}\" >/dev/null 2>&1; do sleep 1; done; \
      else \
        until (echo > /dev/tcp/${POSTGRES_HOST:-postgres}/${POSTGRES_PORT:-5432}) >/dev/null 2>&1; do sleep 1; done; \
      fi; \
      echo 'Postgres available'; \
      if [ -z \"${AIRFLOW__CORE__FERNET_KEY:-}\" ]; then \
        echo 'ERROR: AIRFLOW__CORE__FERNET_KEY not set. Run deploy.sh to create .env or set env var.'; \
        exit 1; \
      fi; \
      if [ ! -f /home/airflow/.initialized ]; then \
        echo 'Initialization flag not found — running airflow db init and creating admin (only once per container)'; \
        airflow db init; \
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true; \
        touch /home/airflow/.initialized || true; \
        echo 'Initialization complete (flag created at /home/airflow/.initialized)'; \
      else \
        echo 'Already initialized inside this container — skipping db init'; \
      fi; \
      echo 'Starting scheduler and webserver'; \
      airflow scheduler & \
      exec airflow webserver \
    "]
    ports:
      - "8080:8080"

  compact-parquet:
    build:
      context: .
      dockerfile: Dockerfile.spark.multistage
    image: compact-parquet:latest
    restart: on-failure
    depends_on:
      - postgres
    environment:
      - SPARK_DRIVER_MEMORY=${SPARK_DRIVER_MEMORY:-20g}
      - SPARK_DRIVER_MEMORY_OVERHEAD=${SPARK_DRIVER_MEMORY_OVERHEAD:-2g}
      - SPARK_LOCAL_DIRS=${SPARK_LOCAL_DIRS:-/tmp/spark_local}
      - CONTAINER_MEM_LIMIT=${CONTAINER_MEM_LIMIT:-24g}
    # Пробрасываем только /data на хост — parquet-файлы будут сохраняться на хосте
    volumes:
      - /data:/data
    ports:
      - "4040:4040"

volumes:
  airflow_logs:
  airflow_plugins:
  postgres_data: